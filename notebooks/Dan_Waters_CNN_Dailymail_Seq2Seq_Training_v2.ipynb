{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dan Waters - CNN Dailymail Seq2Seq Training v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egdm8QqfvQjy"
      },
      "source": [
        "## CSCE 5290 - Fall 2021\n",
        "### Final Project - Part 2\n",
        "Seq2Seq Tutorial adapted to use the CNN/DailyMail dataset.\n",
        "\n",
        "The dataset has been pre-cleaned and truncated in the CNN Process to CSV notebook.\n",
        "Here we just load it straight into a Pandas dataframe for training and split it from there."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnKr9pz4es3e"
      },
      "source": [
        "### Downloading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQThzu6QKBwM"
      },
      "source": [
        "# Install the TF and SpaCy dependencies\n",
        "%%capture\n",
        "!pip install tensorflow-text\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4F1hFzOMGIt"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po1l26MdCyoM",
        "outputId": "e4f7512a-1c0c-42e8-f7d2-bd868de87c81"
      },
      "source": [
        "# Get the data\n",
        "!gdown --id 1tXe-Jh84Nc_RENVzXL-5rAL1SMLJrv7Q"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tXe-Jh84Nc_RENVzXL-5rAL1SMLJrv7Q\n",
            "To: /content/cnn_post_pre_50k.csv\n",
            "100% 115M/115M [00:01<00:00, 108MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdlPnemgu2WK"
      },
      "source": [
        "### Seq2Seq Baseline Model\n",
        "The preprocessing & model code is from this link:\n",
        "https://blog.paperspace.com/introduction-to-seq2seq-models/\n",
        "\n",
        "The intention is to train a fully functional Keras model that can do Seq2Seq abstractive summarization. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "U7TH3W4ODVOG",
        "outputId": "a0abdcc3-3fb9-411c-ae3a-ea10909f0422"
      },
      "source": [
        "post_pre = pd.read_csv('cnn_post_pre_50k.csv')\n",
        "post_pre = post_pre[['text', 'summary']]\n",
        "post_pre.head(5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>by associated press published 14:11 est 25 oct...</td>\n",
              "      <td>sostok _START_ bishop john folda of north dako...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ralph mata was an internal affairs lieutenant...</td>\n",
              "      <td>sostok _START_ criminal complaint cop used his...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>he been accused of making many fashion faux pa...</td>\n",
              "      <td>sostok _START_ prime minister and his family a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>beirut syria carried out an airstrike on refug...</td>\n",
              "      <td>sostok _START_ airstrike kills nine syrians in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>kabul afghanistan china top security official ...</td>\n",
              "      <td>sostok _START_ china top security official vis...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                                            summary\n",
              "0  by associated press published 14:11 est 25 oct...  sostok _START_ bishop john folda of north dako...\n",
              "1   ralph mata was an internal affairs lieutenant...  sostok _START_ criminal complaint cop used his...\n",
              "2  he been accused of making many fashion faux pa...  sostok _START_ prime minister and his family a...\n",
              "3  beirut syria carried out an airstrike on refug...  sostok _START_ airstrike kills nine syrians in...\n",
              "4  kabul afghanistan china top security official ...  sostok _START_ china top security official vis..."
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETOxEjUPszGc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(np.array(post_pre['text']),np.array(post_pre['summary']), test_size=0.1, random_state=128, shuffle=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7n39ulus1Mu"
      },
      "source": [
        "# Tokenize the text to get the vocab count \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Prepare a tokenizer on training data\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn72jQsas7iG",
        "outputId": "8ec914d3-6ce4-47f2-9ba8-0e5409b881ff"
      },
      "source": [
        "thresh = 5\n",
        "\n",
        "cnt = 0\n",
        "tot_cnt = 0\n",
        "\n",
        "for key, value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt = tot_cnt + 1\n",
        "    if value < thresh:\n",
        "        cnt = cnt + 1\n",
        "    \n",
        "print(\"% of rare words in vocabulary: \",(cnt / tot_cnt) * 100)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of rare words in vocabulary:  64.75263170125253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fWj6xuCs9v7",
        "outputId": "08f643c7-10ea-42d7-881d-d3caa3fa3411"
      },
      "source": [
        "max_text_len = 500\n",
        "# Prepare a tokenizer, again -- by not considering the rare words\n",
        "x_tokenizer = Tokenizer(num_words = tot_cnt - cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "# Convert text sequences to integer sequences \n",
        "x_tr_seq = x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq = x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "# Pad zero upto maximum length\n",
        "x_tr = pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val = pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "# Size of vocabulary (+1 for padding token)\n",
        "x_voc = x_tokenizer.num_words + 1\n",
        "\n",
        "print(\"Size of vocabulary in X = {}\".format(x_voc))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary in X = 60673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi9W8-2itAOx"
      },
      "source": [
        "# Prepare a tokenizer on testing data\n",
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmcqQDzrtDDb",
        "outputId": "58100c35-2b64-4d57-c80e-61db8693ae28"
      },
      "source": [
        "thresh = 5\n",
        "\n",
        "cnt = 0\n",
        "tot_cnt = 0\n",
        "\n",
        "for key, value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt = tot_cnt + 1\n",
        "    if value < thresh:\n",
        "        cnt = cnt + 1\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt / tot_cnt) * 100)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of rare words in vocabulary: 69.71909044844186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYpVVjmhtE50",
        "outputId": "2a782c45-1d2d-40d4-e33e-5ae79fcfabbf"
      },
      "source": [
        "max_summary_len = 50\n",
        "# Prepare a tokenizer, again -- by not considering the rare words\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "# Convert text sequences to integer sequences \n",
        "y_tr_seq = y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq = y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "# Pad zero upto maximum length\n",
        "y_tr = pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val = pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "# Size of vocabulary (+1 for padding token)\n",
        "y_voc = y_tokenizer.num_words + 1\n",
        "\n",
        "print(\"Size of vocabulary in Y = {}\".format(y_voc))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary in Y = 19124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0-aD4nmtHqY"
      },
      "source": [
        "# Remove empty Summaries, .i.e, which only have 'START' and 'END' tokens\n",
        "ind = []\n",
        "\n",
        "for i in range(len(y_tr)):\n",
        "    cnt = 0\n",
        "    for j in y_tr[i]:\n",
        "        if j != 0:\n",
        "            cnt = cnt + 1\n",
        "    if cnt == 2:\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr = np.delete(y_tr, ind, axis=0)\n",
        "x_tr = np.delete(x_tr, ind, axis=0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvSyMeQstJ8O"
      },
      "source": [
        "# Remove empty Summaries, .i.e, which only have 'START' and 'END' tokens\n",
        "ind = []\n",
        "for i in range(len(y_val)):\n",
        "    cnt = 0\n",
        "    for j in y_val[i]:\n",
        "        if j != 0:\n",
        "            cnt = cnt + 1\n",
        "    if cnt == 2:\n",
        "        ind.append(i)\n",
        "\n",
        "y_val = np.delete(y_val, ind, axis=0)\n",
        "x_val = np.delete(x_val, ind, axis=0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbZirPFztSIO"
      },
      "source": [
        "### Model Construction and Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gH8yDEBtMG_",
        "outputId": "121d57e9-42c1-4019-b47c-dbc2cdcc6713"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim = 200\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "\n",
        "# Encoder LSTM 1\n",
        "encoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "# Encoder LSTM 2\n",
        "encoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "# Encoder LSTM 3\n",
        "encoder_lstm3 = LSTM(latent_dim, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# Embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# Decoder LSTM\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
        "decoder_outputs, decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 500)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 500, 200)     12134600    ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  [(None, 500, 300),   601200      ['embedding_2[0][0]']            \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm_5 (LSTM)                  [(None, 500, 300),   721200      ['lstm_4[0][0]']                 \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, None, 200)    3824800     ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_6 (LSTM)                  [(None, 500, 300),   721200      ['lstm_5[0][0]']                 \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " lstm_7 (LSTM)                  [(None, None, 300),  601200      ['embedding_3[0][0]',            \n",
            "                                 (None, 300),                     'lstm_6[0][1]',                 \n",
            "                                 (None, 300)]                     'lstm_6[0][2]']                 \n",
            "                                                                                                  \n",
            " time_distributed_1 (TimeDistri  (None, None, 19124)  5756324    ['lstm_7[0][0]']                 \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 24,360,524\n",
            "Trainable params: 24,360,524\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_MLYKwZtanc"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ__8TD3tbUI"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFDoG9wQtdLQ",
        "outputId": "fb72b163-3cbe-499f-b721-511bfcc8c278"
      },
      "source": [
        "# Note: this will take a while. Run as many epochs as needed.\n",
        "history = model.fit([x_tr, y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:,1:], epochs=15, callbacks=[es], batch_size=150, validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "300/300 [==============================] - 1083s 4s/step - loss: 5.4500 - val_loss: 5.0618\n",
            "Epoch 2/15\n",
            "300/300 [==============================] - 1075s 4s/step - loss: 4.9882 - val_loss: 4.7696\n",
            "Epoch 3/15\n",
            "300/300 [==============================] - 1080s 4s/step - loss: 4.7541 - val_loss: 4.5942\n",
            "Epoch 4/15\n",
            "300/300 [==============================] - 1072s 4s/step - loss: 4.5659 - val_loss: 4.4588\n",
            "Epoch 5/15\n",
            "300/300 [==============================] - 1068s 4s/step - loss: 4.4323 - val_loss: 4.3640\n",
            "Epoch 6/15\n",
            "300/300 [==============================] - 1073s 4s/step - loss: 4.3304 - val_loss: 4.2936\n",
            "Epoch 7/15\n",
            "300/300 [==============================] - 1081s 4s/step - loss: 4.2440 - val_loss: 4.2407\n",
            "Epoch 8/15\n",
            "300/300 [==============================] - 1066s 4s/step - loss: 4.1710 - val_loss: 4.1921\n",
            "Epoch 9/15\n",
            "300/300 [==============================] - 1080s 4s/step - loss: 4.1045 - val_loss: 4.1516\n",
            "Epoch 10/15\n",
            "300/300 [==============================] - 1075s 4s/step - loss: 4.0476 - val_loss: 4.1194\n",
            "Epoch 11/15\n",
            "300/300 [==============================] - 1093s 4s/step - loss: 3.9973 - val_loss: 4.0960\n",
            "Epoch 12/15\n",
            "300/300 [==============================] - 1088s 4s/step - loss: 3.9506 - val_loss: 4.0671\n",
            "Epoch 13/15\n",
            "300/300 [==============================] - 1094s 4s/step - loss: 3.9075 - val_loss: 4.0519\n",
            "Epoch 14/15\n",
            "300/300 [==============================] - 1102s 4s/step - loss: 3.8673 - val_loss: 4.0310\n",
            "Epoch 15/15\n",
            "300/300 [==============================] - 1087s 4s/step - loss: 3.8310 - val_loss: 4.0122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "6RhEISn3tfBP",
        "outputId": "428704f1-bb1e-44ec-e376-066287f98600"
      },
      "source": [
        "# Runtime -> Run After from here after training.\n",
        "\n",
        "from matplotlib import pyplot\n",
        "\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jfthbN1thZn"
      },
      "source": [
        "reverse_target_word_index = y_tokenizer.index_word\n",
        "reverse_source_word_index = x_tokenizer.index_word\n",
        "target_word_index = y_tokenizer.word_index"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELJ6lDDmtjI9"
      },
      "source": [
        "# Inference Models\n",
        "\n",
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len, latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs) \n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FL2khIDtlxC"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    \n",
        "  # Encode the input as state vectors.\n",
        "  e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "  \n",
        "  # Generate empty target sequence of length 1\n",
        "  target_seq = np.zeros((1,1))\n",
        "  \n",
        "  # Populate the first word of target sequence with the start word.\n",
        "  target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "  \n",
        "  while not stop_condition:\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "    # Sample a token\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "    \n",
        "    if(sampled_token != 'eostok'):\n",
        "        decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "    # Exit condition: either hit max length or find stop word.\n",
        "    if (sampled_token == 'eostok' or len(decoded_sentence.split()) >= (max_summary_len - 1)):\n",
        "        stop_condition = True\n",
        "\n",
        "    # Update the target sequence (of length 1)\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    # Update internal states\n",
        "    e_h, e_c = h, c\n",
        "\n",
        "  return decoded_sentence"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1mzj9Iotscj"
      },
      "source": [
        "# To convert sequence to summary\n",
        "def seq2summary(input_seq):\n",
        "  newString = ''\n",
        "  for i in input_seq:\n",
        "    if ((i != 0 and i != target_word_index['sostok']) and i!= target_word_index['eostok']):\n",
        "      newString = newString + reverse_target_word_index[i] + ' '\n",
        "          \n",
        "  return newString\n",
        "\n",
        "# To convert sequence to text\n",
        "def seq2text(input_seq):\n",
        "  newString = ''\n",
        "  for i in input_seq:\n",
        "    if i != 0:\n",
        "      newString = newString + reverse_source_word_index[i] + ' '\n",
        "          \n",
        "  return newString"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRK9oD6kt5Ft",
        "outputId": "0ffb1031-d407-447e-8ce6-ea59286081eb"
      },
      "source": [
        "for i in range(0, 5):\n",
        "  print(\"Review:\", seq2text(x_tr[i]))\n",
        "  print(\"Original summary:\", seq2summary(y_tr[i]))\n",
        "  print(\"Predicted summary:\", decode_sequence(x_tr[i].reshape(1, max_text_len)))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: by associated press published 14 11 est 25 october 2013 updated 15 36 est 25 october 2013 the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis virus in late september and early october the state health department has issued an advisory of exposure for anyone who attended five churches and took communion bishop john pictured of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis state immunization program manager molly howell says the risk is low but officials feel it important to alert people to the possible exposure the diocese announced on monday that bishop john is taking time off after being diagnosed with hepatitis the diocese says he contracted the infection through contaminated food while attending conference for newly ordained bishops in italy last month symptoms of hepatitis include fever tiredness loss of appetite nausea and abdominal discomfort fargo catholic diocese in north dakota pictured is where the bishop is located \n",
            "Original summary: start bishop john of north dakota is taking time off after being diagnosed he contracted the infection through contaminated food in italy church members in fargo grand and could have been exposed end \n",
            "Predicted summary:  start the company has been filed for the first time since the outbreak of the virus the company has been linked with the virus the company has been used to the company since the past decade end\n",
            "\n",
            "\n",
            "Review: ralph mata was an internal affairs lieutenant for the miami dade police department working in the division that investigates allegations of wrongdoing by cops outside the office authorities allege that the 45 year old longtime officer worked with drug trafficking organization to help plan murder plot and get guns criminal complaint unsealed in u s district court in new jersey tuesday accuses mata also known as the milk man of using his role as police officer to help the drug trafficking organization in exchange for money and gifts including rolex watch in one instance the complaint alleges mata arranged to pay two assassins to kill rival drug dealers the killers would pose as cops pulling over their targets before shooting them according to the complaint ultimately the organization decided not to move forward with the murder plot but mata still received payment for setting up the meetings federal prosecutors said in statement the complaint also alleges that mata used his police badge to purchase weapons for drug traffickers mata according to the complaint then used contacts at the airport to transport the weapons in his carry on luggage on trips from miami to the dominican republic court documents released by investigators do not specify the name of the drug trafficking organization with which mata allegedly conspired but says the organization has been importing narcotics from places such as ecuador and the dominican republic by hiding them inside shipping containers containing pallets of produce including bananas the organization has been distributing narcotics in new jersey and elsewhere the complaint says authorities arrested mata on tuesday in miami gardens florida it was not immediately clear whether mata has an attorney and police officials could not be immediately reached for comment mata has worked for the miami dade police department since 1992 including directing investigations in miami gardens and working as lieutenant in the k 9 unit at miami international airport according to the complaint since march 2010 he had been working in the internal affairs division mata faces charges of aiding and abetting conspiracy to distribute cocaine conspiring to distribute cocaine and engaging in monetary transactions in property derived from specified unlawful activity he is scheduled to appear in federal court in florida on wednesday if convicted mata could face life in prison cnn suzanne presto contributed to this report \n",
            "Original summary: start criminal complaint cop used his role to help cocaine traffickers ralph mata an internal affairs lieutenant allegedly helped group get guns he also arranged to pay two assassins in murder plot complaint alleges end \n",
            "Predicted summary:  start new york police say they are accused of killing of the murder of the murder he was arrested in the shooting of the shooting in the capital of the two year old was arrested in the capital of the attack end\n",
            "\n",
            "\n",
            "Review: he been accused of making many fashion faux pas while on holiday but the prime minister seems to be deaf to his critics yesterday david cameron was seen in the same pair of beige loafers he wore on holiday last year mr cameron who is in lanzarote with his family the £20 99 shoes from high street store aldo and took them with him to portugal last summer david cameron with samantha yesterday and yes he wearing the same shoes david cameron and samantha in portugal last year where he debuted his beige loafers yesterday he teamed them with casual navy blue shirt and beige shorts on trip to in the centre of the island with wife samantha as ever fashion consultant mrs cameron trumped her husband in the style stakes wearing an elegant black maxi dress and emerald green cardigan the couple and their children nancy arthur and florence are spending six days on the island in £200 a night restored 18th century farmhouse away from the main resorts the prime minister sported no socks with smart black work shoes in one memorable holiday look the couple wear matching trainers while on holiday in granada spain in 2011 the retreat has been styled with an indonesian theme it includes carved buddha statues has its own yoga hall swimming pool hot tub and out’ area with ideal for minister who reputedly has taste for mr cameron has previously been ridiculed for his holiday attire such as wearing smart black work shoes without socks and garish floral shorts refreshment david cameron and his wife samantha stop off for coffee and water during their break in lanzarote jetting off in april the camerons holidayed in lanzarote staying in an upmarket hotel the camerons are holidaying in lanzarote the most eastern canary island \n",
            "Original summary: start prime minister and his family are enjoying an easter break in sported the same £20 99 as he wore in portugal last year pm sat and had drink at beach side cafe on the spanish island end \n",
            "Predicted summary:  start the former british prime minister said he was happy with the pair of the year old son of the royal palace show the pair were also seen together in the uk end\n",
            "\n",
            "\n",
            "Review: beirut syria carried out an airstrike on refugee camp in northern lebanon saturday killing nine syrians and wounding nine more lebanese state run news agency reported the strike centered on syrian refugee camp located near the syrian border between the towns of and in the bekaa valley the national news agency said the red cross took the casualties to universal hospital in saturday strike was not the first by the syrian government which has accused rebels of smuggling arms and supplies across the border on march 18 two syrian jets fired three rockets that hit empty buildings near at the time u s state department spokeswoman called the use of fighter jets to fire rockets into lebanon significant escalation u n commissioner wants to probe into whether syrian rebels executed soldiers also in march the u n security council voiced grave concern over repeated incidents of cross border fire which caused death and injury among the lebanese population incursions abductions and arms trafficking across the lebanese syrian border as well as other border violations the declaration followed briefing by officials on how the conflict in syria has spilled into lebanon more than 600 000 syrians have fled to neighboring lebanon country of about million people according to u n estimate but the lebanese government puts the total at more than million whatever the true figure there is no dispute that the influx has destabilized the area and heightened tensions the attack comes as the syrian conflict is mired in third year of unrest which started in march 2011 when president bashar al assad cracked down on peaceful protesters since then it has evolved into civil war that has killed more than 100 000 and transformed more than million others into refugees according to the red cross read more u n inspectors heading to syria to probe chemical weapons reports cnn nick paton walsh reported this story from beirut and tom watkins wrote it in atlanta cnn hamdi alkhshali and yousuf basil contributed to this report \n",
            "Original summary: start airstrike kills nine syrians in refugee camp state media reports syria has fired into lebanon before the government has accused rebels of smuggling arms across the border with lebanon end \n",
            "Predicted summary:  start new the taliban militants are killed in the attack in the capital of the attack the taliban says the attack is not clear the attack is the most popular in the region end\n",
            "\n",
            "\n",
            "Review: kabul afghanistan china top security official paid surprise visit to afghanistan where he met with president hamid karzai on issues ranging from investment and bilateral trade to to terrorism and drug trafficking china state run news agency said sunday the visit saturday by zhou yongkang member of communist party politburo the elite group of 25 men who run china was the first visit by top chinese official since 1955 xinhua reported beijing kept the visit secret because of security concerns the agency said it is the consistent policy of the chinese government and the party to consolidate and develop china afghanistan relations zhou said in statement reported by xinhua zhou also said china is willing to make due contributions to peace and stability we will continue to provide assistance to afghanistan with no attached conditions and sincerely hope the afghan people can regain peace as soon as possible and build better home in peaceful environment he added karzai and chinese president hu jintao held summit in beijing in june the two countries decided at the time to develop strategic and cooperative partnership xinhua reported \n",
            "Original summary: start china top security official visited afghanistan on saturday and met with president hamid karzai visit was first by top chinese official since 1955 according to china state run xinhua agency china kept the visit secret because of security concerns xinhua said end \n",
            "Predicted summary:  start the u s military says the u s military says the attack is the first time to the united states since the country the country has been linked with the attacks end\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0yVujebzK3B",
        "outputId": "3fc652bb-024c-4622-86ab-171b3dfa69c1"
      },
      "source": [
        "!mkdir -p saved_model\n",
        "model.save('saved_model/seq2seq_cnn_50k')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/seq2seq_cnn_50k/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0102891850> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0102814dd0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f01027ddb50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0102714990> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k32DWNA8S0EJ",
        "outputId": "f14b93f4-271d-4ca3-d1c1-0f3080f556e9"
      },
      "source": [
        "!zip -r seq2seq_cnn_50k.zip saved_model/"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: saved_model/ (stored 0%)\n",
            "  adding: saved_model/seq2seq_cnn_50k/ (stored 0%)\n",
            "  adding: saved_model/seq2seq_cnn_50k/variables/ (stored 0%)\n",
            "  adding: saved_model/seq2seq_cnn_50k/variables/variables.index (deflated 67%)\n",
            "  adding: saved_model/seq2seq_cnn_50k/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: saved_model/seq2seq_cnn_50k/assets/ (stored 0%)\n",
            "  adding: saved_model/seq2seq_cnn_50k/saved_model.pb (deflated 91%)\n",
            "  adding: saved_model/seq2seq_cnn_50k/keras_metadata.pb (deflated 93%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJU1tvl-uDL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21961f41-cc25-4835-aefc-4b99c8f264d2"
      },
      "source": [
        "# Create comparison artifacts for ROUGE scoring\n",
        "limit = 100 # because this takes forever\n",
        "\n",
        "ref_file = 'cnn_ref.txt'\n",
        "pred_file = 'cnn_pred.txt'\n",
        "\n",
        "from tqdm import tqdm\n",
        "with open(ref_file, 'w') as f_ref:\n",
        "  for i, line in enumerate(tqdm(y_tr)):\n",
        "    f_ref.write(seq2summary(y_tr[i]))\n",
        "    if i > limit:\n",
        "      break\n",
        "\n",
        "with open(pred_file, 'w') as f_pred:\n",
        "  for i, line in enumerate(tqdm(x_tr)):\n",
        "    f_pred.write(decode_sequence(x_tr[i].reshape(1, max_text_len)))\n",
        "    if i > limit:\n",
        "      break"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 101/45000 [00:00<00:10, 4190.61it/s]\n",
            "  0%|          | 101/45000 [04:35<34:00:52,  2.73s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH8gXWGhvJ4y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "629b0de8-ebac-476b-c58f-238a2c5b5e4f"
      },
      "source": [
        "!pip install rouge"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlEdijRmvNSj"
      },
      "source": [
        "# Average rouge scoring\n",
        "from rouge import FilesRouge"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDG40FzieVu-"
      },
      "source": [
        "import sys\n",
        "fr = FilesRouge()\n",
        "sys.setrecursionlimit(250 * 250 + 10)\n",
        "scores = fr.get_scores(pred_file, ref_file, avg=True)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEnN9Qnhei5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "999cbb88-f66c-41f8-ca35-67d3755f0a22"
      },
      "source": [
        "scores"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge-1': {'f': 0.2276585093475613,\n",
              "  'p': 0.6514285714285715,\n",
              "  'r': 0.13793103448275862},\n",
              " 'rouge-2': {'f': 0.08788093215853379,\n",
              "  'p': 0.20666666666666667,\n",
              "  'r': 0.0558055805580558},\n",
              " 'rouge-l': {'f': 0.07588616785979305,\n",
              "  'p': 0.21714285714285714,\n",
              "  'r': 0.04597701149425287}}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjnvIj9OT8l3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}